{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directing customers to subscription products through app behaviour analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In todays market, companies have apps that are free but also provide paid versions of the app which have additional features. An example of this is YouTube Red. Since marketing is always costly to companies, it will be beneficial to know exactly who to target with offers and promotions. \n",
    "\n",
    "- **Market:** The target audience are customers who the companys free product. In this case study, this refers to users who downloaded and used the free app.\n",
    "<br>\n",
    "<br>\n",
    "- **Product:** Paid memberships often provide enhanced versions of the free products already given for free, alongside new features. For example, YouTube Red allows you to leave the app while the audio from the video is still playing.\n",
    "<br>\n",
    "<br>\n",
    "- **Goal:** The aim of the model is to predict which users will not subscribe to the paid membership, so that greater marketing efforts can go into trying to convert them to be paid users. This selection of people can be referred to as the 'persuadables'. The term 'persuadables' was used during the Brexit campaign by data scientists who spent effort targetting voters who were deemed to have a Brexit voting probability of around 50% ± p%, where p% was a pre-agreed threshold (e.g. 10%). This was so that voters who were hovering around 50% (on the fence about voting for Brexit) could be pushed into making a firm decision for voting for Brexit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Source:** https://www.kaggle.com/biphili/customer-behavior-app-data-analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dateutil import parser # This is for the date and time fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv('appdata10.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualising the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We observe that the only column with missing data is the enrolled date.\n",
    "\n",
    "sns.heatmap(ds.isnull(), yticklabels = False, cbar = False, cmap = 'Blues' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We observe that the hour column is missing.\n",
    "\n",
    "ds.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.hour = ds.hour.str.slice(1,3).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1 = ds.drop(columns = ['user','screen_list','enrolled_date','first_open','enrolled'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1_columns = []\n",
    "for i in (ds1.columns):\n",
    "    ds1_columns.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1_column_names = []\n",
    "for i in [0,1,4,5,6]:\n",
    "    ds1_column_names.append(ds1_columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1_column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.suptitle('Countplot of Numerical Columns', fontsize = 20)\n",
    "for i in ds1_column_names:\n",
    "    \n",
    "    plt.title(i)\n",
    "    sns.countplot(ds1[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ds.age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ds.numscreens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(ds1.corr(), annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Observations/Interpretation\n",
    "# The later the day of the week, the more likely they are to enrol (but it is very weak correlation so we may not consider this).\n",
    "# The earlier the hour of the day, the more likely they are to enrol.\n",
    "# The younger the age, the more likely they are to enrol.\n",
    "# The higher the number of screens, the more likely they are to enrol.\n",
    "# If they played the minigame, the more likely they are to enrol.\n",
    "# If they used the premium features, the less likely they are to enrol.\n",
    "# If they liked the app, the less likely they are to enrol.\n",
    "\n",
    "ds1.corrwith(ds.enrolled).plot.bar(figsize = (20,10), title = 'Correlation with response variable',\n",
    "                                   fontsize = 15, rot = 45, grid = True,\n",
    "                                   color = ['Blue','Green','Red','Orange','Purple','Brown','Black'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The below is my favourite correlation plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix\n",
    "\n",
    "sns.set(style = 'white', font_scale = 1.3) # Builds the background\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = ds1.corr() # Creating a 2D array of each correlation feature to each other\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype = np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True # This creates a the lower diagonal of the matrix as it is symmetrical\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "fig, axes = plt.subplots(figsize = (12,12)) # Size of the plot\n",
    "fig.suptitle(\"Correlation Matrix\", fontsize = 40) # Title\n",
    "\n",
    "# Generate a custom diverging colourmap\n",
    "\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap = True) # Colouring\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "\n",
    "sns.heatmap(corr, mask = mask, cmap = cmap, vmax = 0.3, center = 0, \n",
    "            square = True, linewidth = 0.5, cbar_kws = {'shrink': 0.5})\n",
    "\n",
    "# As we observe no strong correlation between any variables (linear dependence), we can conclude low multicollinearity.\n",
    "# We will therefore move onto building the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** We wish to have a time limit for enrollments to be considered. This will allow us to valdiate the model within a given timeframe for future datasets.\n",
    "For instance if we set the limit to be one week, we only need to wait one week to validate the accuracy of our model. To examine what time period will be good enough, we will visualise the data for the response times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We wish to compare the dates, therefore requiring us to convert them to datatime objects. \n",
    "# We will be subracting them in order to see how long it took them to enroll.\n",
    "ds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['first_open'] = [parser.parse(i) for i in ds['first_open']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we run this code like the code above it will throw an error due to blanks being present in the dataset.\n",
    "\n",
    "ds['enrolled_date'] = [parser.parse(i) if isinstance(i, str) else i for i in ds['enrolled_date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# astype('timedelta64[h]') converts the time into hours.\n",
    "ds['difference'] = (ds['enrolled_date'] - ds['first_open']).astype('timedelta64[h]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We observe a positive skewed distribution.\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10,6)\n",
    "plt.title('Distribution of time since enrolled')\n",
    "plt.hist(ds['difference'].dropna(), color = 'blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We observe a positive skewed distribution and that most of the enrolments happen\n",
    "# within the first 10 hours. We will therefore set our time limit to two days (48 hours).\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10,6)\n",
    "plt.title('Distribution of time since enrolled')\n",
    "plt.hist(ds['difference'].dropna(), color = 'blue', range = [0,100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will remove all enrolled statues that took over 48 hours.\n",
    "\n",
    "ds.loc[ds.difference > 48, 'enrolled'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.drop(columns = ['difference', 'enrolled_date', 'first_open'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encoding the screen_list columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have obtained data from an analyst which contains the top screens.\n",
    "# We will encorporate this data to make things easier as, encoding the column manually will results in too many columns in the resulting dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_screens = pd.read_csv('top_screens.csv').top_screens.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_screens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We wish to map the screen names from the screen_list to the screens\n",
    "# mentioned in the top_screens dataset.\n",
    "# The comma ',' creates as many commas as there are strings.\n",
    "\n",
    "ds['screen_list'] = ds.screen_list.astype(str) + ','"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if the row contains a top screen. This will return a boolean (True/False) but the \n",
    "# .astype(int) will return 0 or 1.\n",
    "# The second line removes the screens that were included in the top_screen list from the screen_list \n",
    "# and replace it with an empty string.\n",
    "\n",
    "for i in top_screens:\n",
    "    ds[i] = ds.screen_list.str.contains(i).astype(int)\n",
    "    ds['screen_list'] = ds.screen_list.str.replace(i + ',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The other columns will indicate how many left over screens we have.\n",
    "\n",
    "ds['other'] = ds.screen_list.str.count(',')\n",
    "ds = ds.drop(columns = ['screen_list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To reduce multicollinearity betweens screens, we will groups the screens \n",
    "# into Funnels.\n",
    "\n",
    "savings_screens = [\"Saving1\",\n",
    "                    \"Saving2\",\n",
    "                    \"Saving2Amount\",\n",
    "                    \"Saving4\",\n",
    "                    \"Saving5\",\n",
    "                    \"Saving6\",\n",
    "                    \"Saving7\",\n",
    "                    \"Saving8\",\n",
    "                    \"Saving9\",\n",
    "                    \"Saving10\"]\n",
    "ds[\"SavingCount\"] = ds[savings_screens].sum(axis=1)\n",
    "ds = ds.drop(columns=savings_screens)\n",
    "\n",
    "cm_screens = [\"Credit1\",\n",
    "               \"Credit2\",\n",
    "               \"Credit3\",\n",
    "               \"Credit3Container\",\n",
    "               \"Credit3Dashboard\"]\n",
    "ds[\"CMCount\"] = ds[cm_screens].sum(axis=1)\n",
    "ds = ds.drop(columns=cm_screens)\n",
    "\n",
    "cc_screens = [\"CC1\",\n",
    "                \"CC1Category\",\n",
    "                \"CC3\"]\n",
    "ds[\"CCCount\"] = ds[cc_screens].sum(axis=1)\n",
    "ds = ds.drop(columns=cc_screens)\n",
    "\n",
    "loan_screens = [\"Loan\",\n",
    "               \"Loan2\",\n",
    "               \"Loan3\",\n",
    "               \"Loan4\"]\n",
    "ds[\"LoansCount\"] = ds[loan_screens].sum(axis=1)\n",
    "ds = ds.drop(columns=loan_screens)\n",
    "\n",
    "#### Saving Results ####\n",
    "ds.head()\n",
    "ds.describe()\n",
    "ds.columns\n",
    "\n",
    "ds.to_csv('new_appdata10.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv('new_appdata10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ds.enrolled\n",
    "ds = ds.drop(columns = 'enrolled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the dataset into the training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(ds, response, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** At the end of model, we would like the associate the user from which the prediction came from. Before we remove the 'user' column, we will therefore be saving it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_identifier = X_train['user']\n",
    "X_train = X_train.drop(columns = 'user')\n",
    "test_identifier = X_test['user']\n",
    "X_test = X_test.drop(columns = 'user')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** A StandardScaler returns a numpy array of multiple dimensions. The problem with this process is that it loses the columns names and index. The index is how we identify each set of fields to the user, and we would like the column names to be build within our model. We therefore save the scaled part into a different data frame by converting the result of the StandardScaler into its data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = pd.DataFrame(sc_X.fit_transform(X_train))\n",
    "X_test2 = pd.DataFrame(sc_X.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2.columns = X_train.columns.values\n",
    "X_test2.columns = X_test.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2.index = X_train.index.values\n",
    "X_test2.index = X_test.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train2\n",
    "X_test = X_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the Logistic Regression to the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Penalty l1 will penalise any particular field that is strongly correlated to the response variable. If one type of screen is highly correlated to the response variable, the Penalty l1 will penalise this to ensure that particular screen does not end up with a large coefficient in the correlation equations. This is essential with models when working with mobile application screens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(random_state = 0, penalty = 'l1')\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the y_test results\n",
    "\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation - Confusion Matrix and K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm1 = pd.DataFrame(cm, index = (0,1), columns = (0,1))\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.set(font_scale = 1.4)\n",
    "sns.heatmap(cm1, annot = True, fmt = 'g')\n",
    "print('Accuracy Score: %0.4f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = lr, X = X_train, y = y_train, cv = 10)\n",
    "accuracy_mean = accuracies.mean()\n",
    "accuracy_std = accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_mean)\n",
    "print(accuracy_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting the final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat([y_test, test_identifier], axis = 1).dropna()\n",
    "results['predicted_results'] = y_pred\n",
    "results[['user', 'enrolled', 'predicted_results']].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
